{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"TB6sXkNWGYwN"}},{"cell_type":"code","source":["import os\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" #model will be trained on GPU 1"],"metadata":{"id":"aI2lWOWMGZC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import libraries & packages\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import PIL\n","import random\n","from google.colab.patches import cv2_imshow\n","import numpy.random as rng\n","from PIL import Image, ImageDraw, ImageFont, ImageFilter\n","from PIL import Image, ImageOps\n","from sklearn.utils import shuffle\n","import pathlib\n","import os\n","import cv2\n","import math\n","from math import log10, sqrt\n","import glob\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","import skimage\n","from skimage import data\n","from skimage import util\n","from skimage.filters.rank import gradient\n","from skimage.color import rgb2gray\n","from skimage.morphology import disk\n","from scipy import ndimage, misc\n","import scipy.misc\n","from tqdm import tqdm\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers \n","import tensorflow as tf\n","from tensorflow import distribute\n","from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Concatenate, Reshape, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.optimizers import Adadelta, RMSprop, SGD, Adam\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import backend as K\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input, UpSampling2D\n","from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, Conv2D, Reshape, Conv2DTranspose\n","#from tensorflow.keras.layers import Dense, Input, Dropout\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import structural_similarity, peak_signal_noise_ratio, mean_squared_error, mean_squared_error, normalized_root_mse"],"metadata":{"id":"JH8sJ5CtGaCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"R5aDtOWeGaMd","outputId":"7cdc850e-0c1b-4237-bc8e-9078d1fac47a","executionInfo":{"status":"error","timestamp":1657823043034,"user_tz":-60,"elapsed":29158,"user":{"displayName":"Wale Abiodun Ogundeji","userId":"05118496143102978176"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3aeef50c6911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["images = sorted(os.listdir('gdrive/My Drive/images/chestxray'))\n","image_data = []\n","\n","for im in images:\n","  img = image.load_img('gdrive/My Drive/images/chestxray/'+im, target_size = (128,128), color_mode = 'grayscale')\n","  img = image.img_to_array(img)\n","  img = img/255\n","  image_data.append(img)\n","\n","image_dataset = np.array(image_data)"],"metadata":{"id":"eZJNRrmWfaUP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Subplotting images\n","def plot_img(dataset):\n","  f, ax = plt.subplots(1,5)\n","  f.set_size_inches(40,20)\n","  for i in range(5,10):\n","    ax[i-5].imshow(dataset[i].reshape(128, 128), cmap='gray')\n","  plt.show()"],"metadata":{"id":"7tHJOjNzfa3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_img(image_dataset)"],"metadata":{"id":"IjypHyvqf_2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_data = Image.open('/content/gdrive/My Drive/images/chestxray/000001-4.png').convert('L')\n","\n","#Subplotting images\n","width, height = image_data.size\n","plt.subplots(figsize=(10, 6))\n","\n","print('---------------------------------')\n","print('| original image size: %d x %d'%(width,height), '|')\n","print('---------------------------------')\n","plt.imshow(image_data)\n","plt.show()\n","\n","#Resize image to 256x256\n","newwidth = 256\n","newheight = 256\n","#convert to numpy array\n","scaled = np.array(image_data.resize((newwidth, newheight)))\n","plt.subplots(figsize=(10, 6))\n","print('-----------------------------')\n","print('| new image size: %d x %d'%(newwidth,newheight), '|')\n","print('-----------------------------')\n","plt.imshow(scaled)\n","plt.show()"],"metadata":{"id":"COwFlUlSGaPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def noise(image,level):\n","    \"\"\"Adds gaussian random noise\n","    arguments: image, level (level of noise required)\n","    returns: image with level of gaussian noise added\n","    \"\"\"\n","    temp=image+level*np.random.normal(0, 128, size=(image.shape[0],image.shape[1]))\n","    #removing negative pixels (set to zero) and normalising back to 255\n","    regular= temp*(temp>0)\n","    mynorm=255./np.max(temp)\n","    #convert back to integer type\n","    temp = np.around(mynorm*regular).astype('int')\n","    return(temp)\n","\n","#add chosen % of noise to the image\n","amount=0.1 #% of noise required - 0.1 = 10%, 0.05 = 5% etc.\n","noisy_img=noise(scaled,amount)\n","#show the transformation\n","plt.subplots(figsize=(10, 6))\n","print('--------------------------')\n","print('Image with %.4f noise'%(amount),':')\n","print('--------------------------')\n","plt.imshow(noisy_img)\n","plt.show()"],"metadata":{"id":"bDweK_v8Xc2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#using Keras' image_data_generator to create a dataset\n","\n","#add a channel index at the end of each np.array\n","channel1 = np.expand_dims(scaled, 2)\n","#define samples variable as being just one image and add a dimension for this\n","samples= np.expand_dims(channel1, 0)\n","\n","#image data augmentation generator\n","datagen = ImageDataGenerator(rotation_range=10,\n","                             height_shift_range=0.2,\n","                             width_shift_range=0.2,\n","                             fill_mode='constant',)\n","datagen.fit(samples)\n","\n","#create the new dataset including clean, noisy, and very noisy images\n","maxsize=1000 #required size of the dataset\n","\n","#storage arrays\n","clean=[]\n","noisy=[]\n","\n","#instanciating the generator\n","it = datagen.flow(samples, batch_size=1)\n","\n","#add the instances to storage arrays\n","for i in range(maxsize):\n","  new_image=it.next()[0]\n","\n","# normalising the image\n","  clean.append(new_image.astype('float32')/255.)\n","# noise addition to subset of images and normalising \n","  noisy.append(noise(new_image[:,:,0],0.1).astype('float32')/255.)\n","\n","#re-shaping the sets so that they are in the sample, x,y, channel order\n","created_set=np.reshape(clean, [-1, 256,256, 1])\n","noisycreated_set=np.reshape(noisy, [-1, 256,256, 1])"],"metadata":{"id":"IQflPy20GaSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#show outputs\n","\n","#image 16, channel 0: clean (augmented) & noisy (augmented)\n","plt.imshow(created_set[16,:,:,0])\n","plt.show()\n","plt.imshow(noisycreated_set[16,:,:,0])\n","plt.show()\n","\n","#image 97, channel 0: clean (augmented) & noisy (augmented)\n","plt.imshow(created_set[97,:,:,0])\n","plt.show()\n","plt.imshow(noisycreated_set[97,:,:,0])\n","plt.show()"],"metadata":{"id":"yuADeC1_GaWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#splitting the dataset into training and test (70/30)\n","X_train, X_test = train_test_split(created_set, test_size = 0.3, random_state = 42)\n","X_train_noisy, X_test_noisy = train_test_split(noisycreated_set, test_size = 0.3, random_state = 42)"],"metadata":{"id":"SmFuJR_hw7Gm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define custom SSIM Loss function\n","def SSIMLoss(y_true, y_pred):\n","    \"\"\"Defines a custom loss function for SSIM measurement models\n","    Arguments: y_true, the true data, and y_pred, calculated prediction\n","    Returns: SSIMLoss loss function\n","    \"\"\"\n","    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"],"metadata":{"id":"PCbAMeEsw7Je"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#network adapted from https://keras.io/examples/vision/autoencoder/\n","\n","input = Input(shape=channel1.shape)\n","# Encoder\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n","#x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","#x = MaxPooling2D((2, 2), padding='same)(x)\n","#x = Conv2D(8, (3, 3), activation='relu, padding='same)(x)\n","#x = MaxPooling2D((2, 2), padding='same)(x)\n","\n","# Decoder\n","#x = Conv2DTranspose(8, (3, 3), strides=2, activation='relu', padding='same')(x) \n","#reduce strides (2 -> 1) to match removal of max pooling layers on encoder side\n","x = Conv2DTranspose(16, (3, 3), strides=1, activation='relu', padding='same')(x)\n","x = Conv2DTranspose(32, (3, 3), strides=1, activation='relu', padding='same')(x)\n","x = Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n","\n","# Autoencoder\n","autoencoder = Model(input, x)\n","autoencoder.compile(optimizer='adam', loss=SSIMLoss)\n","autoencoder.summary()"],"metadata":{"id":"SmgwYSGmw7PF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","#training the model\n","history = autoencoder.fit(X_train_noisy, X_train, validation_data=(X_test_noisy, X_test), epochs=5, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"IY2OU8lWw7SH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot model losses\n","\n","loss_plt = plt.figure()\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper right')\n","#plt.ylim([0, 1])\n","loss_plt\n","\n"],"metadata":{"id":"ccf-jnlgw7VF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(figsize=(5,5))\n","\n","axs.plot(history.history['loss'])\n","axs.plot(history.history['val_loss'])\n","axs.title.set_text('Training Loss vs Validation Loss')\n","axs.set_xlabel('Epochs')\n","axs.set_ylabel('Loss')\n","axs.legend(['Train','Val'])"],"metadata":{"id":"vyYm8nORKnMI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predict AE output from noisy image\n","noisy_decoded = autoencoder.predict(samples)\n","plt.subplots(figsize=(10, 6))\n","print('---------------------')\n","print('Denoised image output:')\n","print('---------------------')\n","plt.imshow(noisy_decoded[0].reshape(256,256))\n","plt.show()"],"metadata":{"id":"xAFKGYP5K27m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sharpness_measure(imageA, imageB, title): \n","    #adapted from https://dsp.stackexchange.com/questions/35490/how-to-locally-quantify-the-sharpness-of-an-image\n","    \"\"\"function to show the sharpness of 2 side-by-side images as gradient maps\n","    Arguments: 2 images, title\n","    Returns: Plots of the 2 images with the difference in contrast (i.e., sharpness) measured by gradient\n","    \"\"\"\n","    imageA_gray = rgb2gray(imageA)\n","    imageB_gray = rgb2gray(imageB)\n","    disk_matrix = disk(5) #matrix with a disk shape\n","    imageA_sharpness = gradient(imageA_gray, disk_matrix)\n","    imageB_sharpness = gradient(imageB_gray, disk_matrix)\n","    #Show first image\n","    plt.imshow(imageA_sharpness, cmap='viridis')\n","    plt.axis('off')\n","    plt.colorbar()\n","    plt.show()\n","    #show second image\n","    plt.imshow(imageB_sharpness, cmap='viridis')\n","    plt.axis('off')\n","    plt.colorbar()\n","    plt.show()"],"metadata":{"id":"9FUWsmjnK3De"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compare(imageA, imageB, title):\n","\n","  psnr = peak_signal_noise_ratio(imageA, imageB) #, data_range = 255\n","\n","  ssim = structural_similarity(imageA, imageB) #, multichannel=True, data_range = 255\n","\n","  mse = mean_squared_error(imageA, imageB)\n","\n","  nrmse = normalized_root_mse(imageA, imageB) #,  normalization='euclidean'\n","\n","  # setup the figure\n","  fig = plt.figure(title)\n","  print('PSNR: %.2f, SSIM: %.2f, MSE: %.6f, NRMSE: %.4f' % (psnr, ssim, mse, nrmse))\n","  plt.suptitle('PSNR: %.2f, SSIM: %.2f, MSE: %.6f, NRMSE: %.4f' % (psnr, ssim, mse, nrmse))\n","\n","  # show first image\n","  ax = fig.add_subplot(1, 2, 1)\n","  plt.imshow(imageA)\n","  plt.axis('off')\n","\n","  # show the second image\n","  ax = fig.add_subplot(1, 2, 2)\n","  plt.imshow(imageB)\n","  plt.axis('off')\n","\n","  # show the images\n","  plt.show()\n","\n","  #return psnr, ssim, mse, nrmse"],"metadata":{"id":"9hQQuSpuK3HH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalising images for comparison\n","#Normalised_reference = scaled.astype('float32')/255.\n","#Normalised_decoded = noisy_decoded[0].reshape(256,256)/np.max(noisy_decoded[0])\n","#Normalised_noisy_original = noisy_img.astype('float32')/255."],"metadata":{"id":"EBMUfRN-L1wv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalising images for comparison\n","Normalised_reference = scaled.astype('float32')/255.\n","Normalised_decoded = noisy_decoded[0].reshape(256,256)/np.max(noisy_decoded[0])\n","Normalised_noisy_original = noisy_img.astype('float32')/255."],"metadata":{"id":"OH_OEWbO6UcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compare images clean reference with de-noised\n","plt.subplots(figsize=(10, 6))\n","compare (Normalised_reference, Normalised_decoded,'')\n","#ideally want mse to be close to 0, ssim to be close to 1 "],"metadata":{"id":"oADKMFzgN4FJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Compare images clean reference with noisy original\n","plt.subplots(figsize=(10, 6))\n","compare(Normalised_reference, Normalised_noisy_original,'')"],"metadata":{"id":"AR-WsvieOKBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sharpness measure: shows the sharpness of the original non-noisy image vs the output as a gradient\n","sharpness_measure(Normalised_reference, Normalised_decoded,'') "],"metadata":{"id":"bT_oAiX3O9J-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["median_filter = ndimage.median_filter(X_train[0].reshape(256, 256), size= 5) \n","\n","bilateral_filter = cv2.bilateralFilter(X_train[0].reshape(256, 256), 5, 50, 50)"],"metadata":{"id":"EyIqJvEIPfVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show first image\n","ax = fig.add_subplot(1, 2, 1)\n","plt.imshow(median_filter)\n","plt.axis('off')\n","\n","# show the second image\n","ax = fig.add_subplot(1, 2, 2)\n","plt.imshow(bilateral_filter)\n","plt.axis('off')\n","\n","# show the images\n","plt.show()"],"metadata":{"id":"eXVmpoV1Pku2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1RpXDvL-w7Xt"},"execution_count":null,"outputs":[]}]}